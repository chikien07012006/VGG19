# -*- coding: utf-8 -*-
"""Xy_dung_CNN_(2).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UiZogAqfhjOyabmn4h4RJ0OSBn8zAIRf
"""

from torch.utils.data import Dataset, TensorDataset
from torchvision  import datasets, transforms
import os
from PIL import Image
from torch.utils.data import DataLoader
from matplotlib import pyplot as plt
from torchvision.transforms import ToTensor, Resize, Compose
import torch.nn as nn
import torch
from sklearn.model_selection import train_test_split
from tqdm.autonotebook import tqdm
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix

data_path = r"C:\Users\Administrator\Desktop\DATASET\Deep Learning\VGG19\animals"

# Load từng bức ảnh một
class MyDataset(Dataset):
  def __init__(self, path, transform):
    self.path = path
    self.x_train = []
    self.y_train = []
    self.classes = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]
    print(self.classes)
    self.transform = transform

    for label, class_name in enumerate(self.classes):
      new_path = os.path.join(path, class_name)
      for img_name in os.listdir(new_path):
        image_path = os.path.join(new_path, img_name)
        self.x_train.append(image_path)
        self.y_train.append(label)

  def __len__(self):
    return len(self.y_train)

  def __getitem__(self, idx):  # transform qua dạng tensor ở hàm getitem thì mới chạy được (để khi nào cần thì mới transform, tiết kiệm tài nguyên tính toán) =)))))))))))
    label = self.y_train[idx]
    image = self.x_train[idx]
    image = Image.open(image).convert("RGB") # convert RGB để xử lý phần ảnh transparent ( có 4 kênh màu )
    image = self.transform(image)

    return label, image

class MyDataset_train_test(Dataset):
  def __init__(self, image, label, transform):
    self.image = image
    self.label = label
    self.transform = transform
  def __len__(self):
    return len(self.label)
  def __getitem__(self, idx):
    label = self.label[idx]
    image = self.image[idx]
    image = Image.open(image).convert("RGB")
    image = self.transform(image)
    return image, label

data = MyDataset(data_path, transform=Compose([Resize((127, 127)), ToTensor()]))
num_classes = len(data.classes)
x_train, x_test, y_train, y_test = train_test_split(data.x_train, data.y_train, test_size=0.2, random_state=32)
train = MyDataset_train_test(x_train, y_train, transform=Compose([Resize((64, 64)), ToTensor()]))
test = MyDataset_train_test(x_test, y_test, transform=Compose([Resize((64, 64)), ToTensor()]))
train = DataLoader(train, batch_size=16, shuffle=True)
test = DataLoader(test, batch_size=16, shuffle=True)

class FCN(nn.Module):
    def __init__(self, num_classes=10):
        super().__init__()
        self.conv1 = self.block1(in_channels=3, out_channels=64)
        self.conv2 = self.block2(in_channels=64, out_channels=128)
        self.conv3 = self.block3(in_channels=128, out_channels=256)
        self.conv4 = self.block4(in_channels=256, out_channels=512)
        self.conv5 = self.block5(in_channels=512, out_channels=512)

        self.fc1 = nn.Sequential(
            nn.Dropout(p=0.5),
            nn.Linear(in_features=2048, out_features=4096),
            nn.LeakyReLU()
        )
        self.fc2 = nn.Sequential(
            nn.Dropout(p=0.5),
            nn.Linear(in_features=4096, out_features=4096),
        )
        self.fc3 = nn.Sequential(
            nn.Dropout(p=0.5),
            nn.Linear(in_features=4096, out_features=num_classes),
        )


    def block1(self, in_channels, out_channels):
      return nn.Sequential(
        nn.Conv2d(in_channels=in_channels, out_channels=out_channels, padding="same", stride=1, kernel_size=3),
        nn.ReLU(),
        nn.Conv2d(in_channels=out_channels, out_channels=out_channels, padding="same", stride=1, kernel_size=3),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2)
      )

    def block2(self, in_channels, out_channels):
      return nn.Sequential(
        nn.Conv2d(in_channels=in_channels, out_channels=out_channels, padding="same", stride=1, kernel_size=3),
        nn.ReLU(),
        nn.Conv2d(in_channels=out_channels, out_channels=out_channels, padding="same", stride=1, kernel_size=3),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2)
      )
      
    def block3(self, in_channels, out_channels):
      return nn.Sequential(
        nn.Conv2d(in_channels=in_channels, out_channels=out_channels, padding="same", stride=1, kernel_size=3),
        nn.ReLU(),
        nn.Conv2d(in_channels=out_channels, out_channels=out_channels, padding="same", stride=1, kernel_size=3),
        nn.ReLU(),
        nn.Conv2d(in_channels=out_channels, out_channels=out_channels, padding="same", stride=1, kernel_size=3),
        nn.ReLU(),
        nn.Conv2d(in_channels=out_channels, out_channels=out_channels, padding="same", stride=1, kernel_size=3),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2)
      )
    
    def block4(self, in_channels, out_channels):
      return nn.Sequential(
        nn.Conv2d(in_channels=in_channels, out_channels=out_channels, padding="same", stride=1, kernel_size=3),
        nn.ReLU(),
        nn.Conv2d(in_channels=out_channels, out_channels=out_channels, padding="same", stride=1, kernel_size=3),
        nn.ReLU(),
        nn.Conv2d(in_channels=out_channels, out_channels=out_channels, padding="same", stride=1, kernel_size=3),
        nn.ReLU(),
        nn.Conv2d(in_channels=out_channels, out_channels=out_channels, padding="same", stride=1, kernel_size=3),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2)
      )
      
    def block5(self, in_channels, out_channels):
      return nn.Sequential(
        nn.Conv2d(in_channels=in_channels, out_channels=out_channels, padding="same", stride=1, kernel_size=3),
        nn.ReLU(),
        nn.Conv2d(in_channels=out_channels, out_channels=out_channels, padding="same", stride=1, kernel_size=3),
        nn.ReLU(),
        nn.Conv2d(in_channels=out_channels, out_channels=out_channels, padding="same", stride=1, kernel_size=3),
        nn.ReLU(),
        nn.Conv2d(in_channels=out_channels, out_channels=out_channels, padding="same", stride=1, kernel_size=3),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2)
      )

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = self.conv4(x)
        x = self.conv5(x)
        x = x.view(x.shape[0], -1)
        x = self.fc1(x)
        x = self.fc2(x)
        x = self.fc3(x)
        return x

if torch.cuda.is_available():
    device = torch.device("cuda")
    print("ok")
else:
    device = torch.device("cpu") 

model = FCN().to(device)
optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)
cr = nn.CrossEntropyLoss()

start_epoch = 0
acc = 0
if os.path.exists(r"C:\Users\Administrator\Desktop\DATASET\Deep Learning\VGG19\trained_model_cnn\last_cnn.pt"):
  checkpoint = torch.load(r"C:\Users\Administrator\Desktop\DATASET\Deep Learning\VGG19\trained_model_cnn\last_cnn.pt")
  start_epoch = checkpoint["epoch"]
  model.load_state_dict(checkpoint["model"])
  optimizer.load_state_dict(checkpoint["optimizer"])
  acc = checkpoint["acc"]

for image, label in train:
    print(image.shape)
    print(label.shape)
    break
total_images = len(test.dataset)
print(f"Tổng số ảnh: {total_images}")

best_acc = acc

for i in range(start_epoch, 30):
  total = 0
  model.train()
  progress_bar = tqdm(train, colour = "green")
  for iter, (image, label) in enumerate(progress_bar):
    image = image.to(device)
    label = label.to(device)
    output = model(image)
    loss = cr(output, label)
    #print(f"Epoch: {iter}/{len(train)}, Loss: {loss}")
    loss.backward()
    optimizer.step()
    optimizer.zero_grad()
    progress_bar.set_description("Epoch {}/{}. Iteration {}/{}. Loss {:.3f}".format(i+1, 30, iter+1, len(train), loss))

  model.eval()
  all_label = []
  all_pred = []
  for iter, (image, label) in enumerate(test):
    image = image.to(device)
    label = label.to(device)
    all_label.extend(label)
    with torch.no_grad(): #kh tính gradient ở bước test model
      output = model(image) #Mô hình dự đoán kết quả đầu ra
      predicted = torch.argmax(output, dim=1) #Chọn nhãn có xác suất cao nhất.
      all_pred.extend(predicted)
  all_label = [label.item() for label in all_label]
  all_pred = [prediction.item() for prediction in all_pred]
  accuracy = accuracy_score(all_label, all_pred)
  checkpoint = {
    "model": model.state_dict(),
    "optimizer": optimizer.state_dict(),
    "acc": accuracy,
    "epoch": i + 1
  }
  torch.save(checkpoint, r"C:\Users\Administrator\Desktop\DATASET\Deep Learning\VGG19\trained_model_cnn\last_cnn.pt")
  if accuracy > best_acc:
    best_acc = accuracy
    checkpoint = {
    "model": model.state_dict(),
    "optimizer": optimizer.state_dict(),
    "epoch": i + 1,
    "acc": accuracy
    }
    torch.save(checkpoint, r"C:\Users\Administrator\Desktop\DATASET\Deep Learning\VGG19\trained_model_cnn\best_cnn.pt")

  #Vì label_true và prediction có thể là torch.Tensor, cần chuyển về danh sách số nguyên.
  print("Epoch {}: Accuracy: {}".format(i+1, accuracy))
